# crawlit environment variables
# Copy this file to .env and fill in the values for your environment.
# All variables are optional unless noted as REQUIRED.

# ──────────────────────────────────────────
# Crawler defaults
# ──────────────────────────────────────────

# User-Agent string sent with every HTTP request
CRAWLIT_USER_AGENT=crawlit/1.0

# Default request delay in seconds (float)
CRAWLIT_DELAY=0.1

# Default request timeout in seconds (int)
CRAWLIT_TIMEOUT=10

# Default maximum crawl depth (int)
CRAWLIT_MAX_DEPTH=3

# Default maximum concurrent requests for async crawler (int)
CRAWLIT_MAX_CONCURRENT=5

# ──────────────────────────────────────────
# Proxy settings
# ──────────────────────────────────────────

# HTTP/HTTPS proxy URL, e.g. http://proxy.example.com:8080
CRAWLIT_PROXY=

# ──────────────────────────────────────────
# Logging
# ──────────────────────────────────────────

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
CRAWLIT_LOG_LEVEL=INFO

# Path to log file (leave empty to log only to stdout)
CRAWLIT_LOG_FILE=

# ──────────────────────────────────────────
# PostgreSQL storage backend
# ──────────────────────────────────────────

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=crawlit
POSTGRES_USER=crawlit
POSTGRES_PASSWORD=

# ──────────────────────────────────────────
# MongoDB storage backend
# ──────────────────────────────────────────

MONGO_URI=mongodb://localhost:27017
MONGO_DB=crawlit

# ──────────────────────────────────────────
# RabbitMQ (distributed crawling)
# ──────────────────────────────────────────

RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest
RABBITMQ_VHOST=/

# ──────────────────────────────────────────
# Apache Kafka (distributed crawling)
# ──────────────────────────────────────────

KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=crawlit_urls

# ──────────────────────────────────────────
# Cache settings
# ──────────────────────────────────────────

# Page cache TTL in seconds (int)
CRAWLIT_CACHE_TTL=3600

# Directory for disk-based page cache
CRAWLIT_CACHE_DIR=.crawlit_cache

# ──────────────────────────────────────────
# Incremental / resume settings
# ──────────────────────────────────────────

# File path for persisting crawl state between runs
CRAWLIT_STATE_FILE=crawl_state.json
