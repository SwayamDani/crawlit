# ğŸ•·ï¸ crawlit - Modular, Ethical Python Web Crawler

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

A powerful, modular, and ethical web crawler built in Python. Designed for security testing, link extraction, and website structure mapping with a focus on clean architecture and extensibility.

## ğŸš€ Features

- **Modular Architecture**: Easily extend with custom modules and parsers
- **Ethical Crawling**: Configurable robots.txt compliance and rate limiting
- **Depth Control**: Set maximum crawl depth to prevent excessive resource usage
- **Domain Filtering**: Restrict crawling to specific domains or subdomains
- **Robust Error Handling**: Gracefully manage connection issues and malformed pages
- **Multiple Output Formats**: Export results as JSON, CSV, or plain text
- **Detailed Logging**: Comprehensive logging of all crawler activities
- **Command Line Interface**: Simple, powerful CLI for easy usage

## ğŸ“‹ Requirements

- Python 3.8+
- Dependencies (will be listed in requirements.txt)

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/SwayamDani/crawlit.git
cd crawlit

# Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“˜ Usage

### Basic Usage`

```bash
python crawlit.py --url https://example.com
```

### Advanced Options

```bash
python crawlit.py --url https://example.com \
                 --depth 3 \
                 --output-format json \
                 --output-file results.json \
                 --respect-robots \
                 --delay 0.5 \
                 --user-agent "crawlit/1.0" \
                 --internal-only
```

### Command Line Arguments

| Argument | Description | Default |
|----------|-------------|---------|
| `--url`, `-u` | Target website URL | Required |
| `--depth`, `-d` | Maximum crawl depth | 3 |
| `--output-format`, `-f` | Output format (json, csv, txt) | json |
| `--output-file`, `-o` | File to save results | crawl_results.json |
| `--respect-robots`, `-r` | Respect robots.txt rules | False |
| `--delay` | Delay between requests (seconds) | 0.1 |
| `--user-agent` | Custom User-Agent string | crawlit/1.0 |
| `--internal-only`, `-i` | Only crawl URLs within the same domain | True |
| `--verbose`, `-v` | Verbose output | False |
| `--help`, `-h` | Show help message | - |

## ğŸ—ï¸ Project Structure

```
crawlit/
â”œâ”€â”€ crawlit.py           # Main entry point
â”œâ”€â”€ requirements.txt     # Project dependencies
â”œâ”€â”€ crawler/             # Core crawler modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py        # Core crawler logic
â”‚   â”œâ”€â”€ fetcher.py       # HTTP request handling
â”‚   â”œâ”€â”€ parser.py        # HTML parsing and link extraction
â”‚   â”œâ”€â”€ robots.py        # Robots.txt parser
â”‚   â””â”€â”€ utils.py         # Utility functions
â”œâ”€â”€ output/              # Output formatters
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ json_formatter.py
â”‚   â”œâ”€â”€ csv_formatter.py
â”‚   â””â”€â”€ text_formatter.py
â””â”€â”€ tests/               # Unit and integration tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_crawler.py
    â”œâ”€â”€ test_parser.py
    â””â”€â”€ test_robots.py
```

## ğŸ“… Project Timeline

- **May 2025**: Initial structure and CLI setup
- **June 2025**: Core functionality complete (HTTP handling, parsing, domain control)
- **June 30, 2025**: Project completion target with all core features

## ğŸ¤ Contributing

Contributions will be welcome after the core functionality is complete. Please check back after June 30, 2025, for contribution guidelines.

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¤ Author

Built and maintained by Swayam Dani

---

**Note**: This project is under active development with completion targeted for June 30, 2025.